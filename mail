Dear Colleagues (bcc),

Please be informed that EDI Fundamentals Mandatory training 3/3 (3d part of 3 of EDI Fundamentals) was assigned to you in LSEG Workday Portal (LSEG environment).

Kindly asking you to complete the learning ASAP If you’ve already completed the course – please ignore the email.
•	The training is not visible in the LSEG Workday Portal in “My Learning” tab as a mandatory, so you should access course by clicking the direct link ( from the LSEG environment) :https://wd3.myworkday.com/lseg/d/inst/1$17188/23455$2185.htmld  
An additional reminder was sent to your LSEG email address as well.

Please pay attention that the course consists of 2 chapters, kindly make sure you’ve completed each of them:


{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "Service": "export.rds.amazonaws.com"
            },
            "Action": "sts:AssumeRole"
        }
    ]
}


AWS Lambda + CloudWatch Events

storing a timestamp in AWS Systems Manager Parameter Store along with the key-value data. Then, use a scheduled cleanup job (e.g., AWS Lambda + CloudWatch Events) to remove expired parameters.


Hi Atul, just a quick heads-up that we've made a minor alteration to the Log Level Controller architecture. In addition to writing the updated log level to Param Store, the GitLab pipeline should also now hit a wehook HTTP(s) endpoint on the log level controller. The webhook endpoint will then trigger the log level controller app to fetch the updated log level from the param store. It should no longer poll the param store for cost reasons meaning that it will need to persist the log level in-memory for the TTL recorded in the param store on-collection. In a situation when the log level controller starts up, the first thing it should do is check param store to see if there is a set log level. This covers a situation where the controller may potentially crash. I've updated the architecture diagram here and sequenced the key interactions: RFC - Log Level Controller - Index Platform and Portfolio Services (IPPS) - Confluence



Hi Katiyar, Atulkumar (External), I don't think there's a need to remove / clean up the expired parameter. Simply recording the expiry date/time is sufficient. The log level controller will know whether to use or ignore set log level depending on whether the expiry date/time has passed.
 
Let's keep it simple for now given that this is the only use-case we currently have for dynamic configs with an expiry.



stages:
  - save-config
  - notify-app

variables:
  PACKAGE_NAME: "default-package"
  LOG_LEVEL: "INFO"
  EXPIRY_TIME: "600000"  # 10 minutes (in milliseconds)
  WEBHOOK_URL: "https://your-spring-boot-app.com/api/refresh-log-level"

save-config:
  stage: save-config
  script:
    - echo "Storing log level in AWS Parameter Store..."
    - TIMESTAMP=$(date +%s)  # Capture current timestamp
    - aws ssm put-parameter --name "/log-config/${PACKAGE_NAME}" --value "${LOG_LEVEL}" --type "String" --overwrite
    - aws ssm put-parameter --name "/log-config/${PACKAGE_NAME}/expiry" --value "$((TIMESTAMP + (EXPIRY_TIME / 1000)))" --type "String" --overwrite
    - echo "Parameter stored successfully!"

notify-app:
  stage: notify-app
  script:
    - echo "Triggering webhook to refresh log level..."
    - RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" -X POST "$WEBHOOK_URL" -H "Content-Type: application/json" -d '{"packageName": "'"$PACKAGE_NAME"'"}')
    - if [ "$RESPONSE" -eq 200 ]; then
        echo "Webhook successfully triggered!";
      else
        echo "Webhook failed with response code $RESPONSE";
        exit 1;
      fi



@RestController
@RequestMapping("/api")
public class LogConfigController {

    @PostMapping("/refresh-log-level")
    public ResponseEntity<String> refreshLogLevel(@RequestBody Map<String, String> request) {
        String packageName = request.get("packageName");
        if (packageName == null || packageName.isEmpty()) {
            return ResponseEntity.badRequest().body("Package name is missing");
        }

        try {
            AWSSimpleSystemsManagement ssmClient = AWSSimpleSystemsManagementClientBuilder.defaultClient();
            GetParameterRequest requestLogLevel = new GetParameterRequest().withName("/log-config/" + packageName);
            String logLevel = ssmClient.getParameter(requestLogLevel).getParameter().getValue();

            // Call service to update log level dynamically
            updateLogLevel(packageName, logLevel);

            return ResponseEntity.ok("Log level updated for package: " + packageName);
        } catch (Exception e) {
            return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).body("Error fetching log level: " + e.getMessage());
        }
    }

    private void updateLogLevel(String packageName, String logLevel) {
        Logger logger = LoggerFactory.getLogger(packageName);
        ((ch.qos.logback.classic.Logger) logger).setLevel(Level.toLevel(logLevel));
    }
}


 

notify-app:
  stage: notify-app
  script:
    - echo "Triggering webhook to refresh log level..."
    - >-
      RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" 
      -X POST "$WEBHOOK_URL" 
      -H "Content-Type: application/json" 
      -d "{\"packageName\":\"$PACKAGE_NAME\"}")
    - |
      if [ "$RESPONSE" -eq 200 ]; then
        echo "Webhook successfully triggered!"
      else
        echo "Webhook failed with response code $RESPONSE"
        exit 1
      fi


Error fetching log level: Service returned error code ParameterNotFound (Service: Ssm, Status Code: 400, Request ID: 7d4ebf71-bdff-4e9c-be11-d72932fc5561)

GetParameterRequest requestLogLevel = GetParameterRequest.builder().name("/log-config/" + packageName).build();
            String logLevel = ssmClient.getParameter(requestLogLevel).parameter().value();
